{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Partitionnement de données\n",
    "*PASS 2022-2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ascendante hiérarchique (CAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe de l'approche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe de la Classification Hiérarchique Ascendante [Wikipedia](https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique) consiste à regrouper les éléments par fusion itérative de clusters.\n",
    "\n",
    "Il s'agit donc d'une approche agglomérative lors de laquelle, à chaque étape, les deux clusters les plus proches sont fusionnés.\n",
    "\n",
    "Pour réaliser cela, il faut déterminer:\n",
    "   - la forme des clusters initiaux,\n",
    "   - la métrique permettant de claculer la distance entre les clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le principe générale de l'algotithme est le suivant:\n",
    "- Au départ chaque point du jeu de données défini un cluster ne contenant qu'un seul point,\n",
    "- Ensuite, itérativement, l'algorithme procède à la fusion des clusters les plus proches en utulisant la distance en cluster choisie.\n",
    "- Le programme s'arrête lorsque le nombre de clusters atteint la limite $k$ spécifiée en paramètre de l'algorithme.\n",
    "\n",
    "<img src=img/figure_CAH_algo.png></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarques\n",
    "\n",
    "<span style=\"color:midnightblue\">\n",
    "\n",
    "<u>**Remarque 1 :**</u>\n",
    "\n",
    "Si $k=1$ le cluster final contient tous les points.\n",
    "\n",
    "<u>**Remarque 2 :**</u>\n",
    "\n",
    "Les fusions entres clusters sont généralement représentées sous forme d'un *dendrogramme*. Il s'agit d'un arbre dont:\n",
    "   - les feuilles représentent les données à regrouper,\n",
    "   - les noeuds représentent des clusters issus des fusions successives. Chaque cluster contient l'ensemble des points (feuilles) qui sont des descendants du noeud correspondant.\n",
    "   \n",
    "Classiquement, dans ce type de représentation, les arrêtes entre 2 cluster enfants $c_i$, $c_j$ (ceux qui sont regroupés) et le cluster parent $c_{i\\_j}$ (celui qui représente le regroupement), ont une hauteur proportionnelle à la distance entre les deux clusters enfants fusionnés $c_i$, $c_j$.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de déroulement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "\n",
    "<u>***Cas d'étude:***</u>\n",
    "\n",
    "Soit un jeu de données $\\mathcal{D}$ contenant $N=7$ étudiants $\\mathcal{D}=\\{x_i \\}_{i\\in 1..7}$ décrits par les moyennes de $d=2$ UE.\n",
    "\n",
    "<u>Initialisation de la procédure:</u>\n",
    "    \n",
    "On initialise la partition $C_0$ avec 7 clusters contenant chacun un des 7 étudiants du jeu de données $\\mathcal{D}$  :\n",
    "\\begin{align}\n",
    "    \\left|C_0\\right| &= \\{ c_1,\\; c_2,\\; c_3,\\; c_4,\\; c_5,\\; c_6,\\; c_7\\}\\\\\n",
    "      &= \\{ \\{x_1\\},\\; \\{x_2\\},\\; \\{x_3\\},\\; \\{x_4\\},\\; \\{x_5\\},\\; \\{x_6\\},\\; \\{x_7\\}\\}\n",
    "\\end{align}\n",
    "\n",
    "<u>Itération 1:</u>\n",
    "- $\\left|\\mathcal{C_0}\\right| = 7 > k$,\n",
    "- Les distances entre chaque clusters (deux à deux), sont calculées (représentée ci-dessous dans la matrice de distances).\n",
    "- Ces calculs mettent en écidence que les clusters $c_1$ et $c_2$ sont les clusters les plus proches avec une distance inter-cluster $dist(c_1, c_2)=0.7$\n",
    "- Les cluster $c_1$ et $c_2$ fusionnent en un cluster unique $c_{1,2}$ au terme de cette itération.\n",
    "\n",
    "<img src=\"./img/CAH_0.png\" width=\"80%\"></br>\n",
    "On met à jour la partition :\n",
    "$C_1=\\{ \\; c_3,\\; c_4,\\; c_5,\\; c_6,\\; c_7, c_{1,2}\\}=\\{ \\{x_3\\},\\; \\{x_4\\},\\; \\{x_5\\},\\; \\{x_6\\},\\; \\{x_7\\},\\; \\{x_1,x_2\\}\\}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "\n",
    "<u>Itération 2:</u>\n",
    "\n",
    "- $\\left|\\mathcal{C_1}\\right| = 6 > k$,\n",
    "- Les distances entre chaque clusters (deux à deux), sont calculées (représentée ci-dessous dans la matrice de distances).\n",
    "- Ces calculs mettent en écidence que les clusters $c_4$ et $c_7$ sont les clusters les plus proches avec une distance inter-cluster $dist(c_4, c_7)=1.1$\n",
    "- Les cluster $c_4$ et $c_7$ fusionnent en un cluster unique $c_{4,7}$ au terme de cette itération.\n",
    "\n",
    "<img src=\"./img/CAH_1.png\" width=\"80%\"></br>\n",
    "On met à jour la partition :\n",
    "$C_2=\\{ c_3,\\; c_5,\\; c_6,\\; c_{1,2},\\; c_{4,7}\\}=\\{ \\{x_3\\},\\; \\{x_5\\},\\; \\{x_6\\},\\; \\{x_1,x_2\\},\\; \\{x_4, x_7\\}\\}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "\n",
    "<u>Itération 3:</u>\n",
    "\n",
    "- $\\left|\\mathcal{C_2}\\right| = 5 > k$,\n",
    "- Les distances entre chaque clusters (deux à deux), sont calculées (représentée ci-dessous dans la matrice de distances).\n",
    "- Ces calculs mettent en écidence que les clusters $c_5$ et $c_6$ sont les clusters les plus proches avec une distance inter-cluster $dist(c_5, c_6)=1.7$\n",
    "- Les cluster $c_5$ et $c_6$ fusionnent en un cluster unique $c_{5,6}$ au terme de cette itération.\n",
    "\n",
    "<img src=\"./img/CAH_2.png\" width=\"80%\"></br>\n",
    "On met à jour la partition :\n",
    "$C_3=\\{ c_3,\\; c_{1,2},\\; c_{4,7},\\; c_{5,6}\\}=\\{ \\{x_3\\},\\; \\{x_1,x_2\\},\\; \\{x_4, x_7\\},\\; \\{x_5,x_6\\}\\}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "\n",
    "<u>Itération 4:</u>\n",
    "\n",
    "- $\\left|\\mathcal{C_3}\\right| = 4 > k$,\n",
    "- Les distances entre chaque clusters (deux à deux), sont calculées (représentée ci-dessous dans la matrice de distances).\n",
    "- Ces calculs mettent en écidence que les clusters $c_3$ et $c_{4,7}$ sont les clusters les plus proches avec une distance inter-cluster $dist(c_3, c_{4,7})=3.8$\n",
    "- Les cluster $c_3$ et $c_{4,7}$ fusionnent en un cluster unique $c_{3,4,7}$ au terme de cette itération.\n",
    "\n",
    "<img src=\"./img/CAH_3.png\" width=\"80%\"></br>\n",
    "On met à jour la partition :\n",
    "$C_4=\\{ c_{1,2},\\; c_{5,6},\\; c_{3,4,7}\\}=\\{ \\{x_1,x_2\\},\\; \\{x_5,x_6\\},\\; \\{x_3, x_4, x_7\\}\\}$\n",
    "\n",
    "\n",
    "et ainsi de suite tant qu'il reste des clusters a fusioner...\n",
    "<img src=\"./img/CAH_4.png\" width=\"80%\"></br>\n",
    "<img src=\"./img/CAH_5.png\" width=\"80%\"></br>\n",
    "<img src=\"./img/CAH_6.png\" width=\"80%\"></br>\n",
    "\n",
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Input**</u>\n",
    "- $\\mathcal{D}$ un jeu de données\n",
    "- dist une fonction de distance entre classes/clusters\n",
    "- $k$ le nombre de classe à former.\n",
    "\n",
    "<u>**Output**</u>\n",
    "- une classification $\\mathcal{C}$ contenant $k$ classes/clusters\n",
    "\n",
    "<u>**Algorithme**</u>\n",
    "- Initialisation: Chaque élément du jeu de données $\\mathcal{D}$ forme un cluster:<br>$\\mathcal{C}=\\{ c_i = \\{x_i\\}\\}_{x_i\\in \\mathcal{D}}$\n",
    "\n",
    "- Tant que $\\left|\\mathcal{C}\\right| \\gt k$\n",
    "    - Calculer $M$ la matrice de distance entre chaque couple $(c_k,cl) \\in C^2$<br>$M = (m_{i,j})$ avec $m_{(i,j)}=dist(c_i,c_j)$ et $(c_i,c_j)\\in \\mathcal{C}^2$\n",
    "    - identifier au moyen de $M$ les deux clusters $(i,j)$ les plus proches:\n",
    "$$\\underset{i,j, i\\neq j}{\\text{arg min }} dist(c_i,c_j)$$\n",
    "    - fusionner les deux clusters les plus proches $c_{i}, c_{j}$<br>\n",
    "    $$c_{i,j} =c_{i} \\cup c_{j}$$\n",
    "    - Mettre à jour la liste des clusters en retirant les clusters $c_{i}$ et $c_{j}$ qui ont fusionnés et en ajoutant le cluster fusionné $c_{i,j}$:\n",
    "    $$\\mathcal{C} = (\\mathcal{C} \\backslash \\{c_{i},c_{j}\\} ) \\cup \\{c_{i,j}\\})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkgreen\">\n",
    "    \n",
    "<u>**Exercice(s) :**</u>\n",
    "\n",
    "- Exercice TD : Construction d'un dendrogramme\n",
    "- Exercice TP: Programmation du clustering hiérarchique\n",
    "- Exercice TP: Comparer les effets de la fonction de distance inter-cluster\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Défintion du nombre de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs startégies peuvent être employées pour fixer le nombre de classes (clusters):\n",
    "- fixer le nombre de clusters $k$ *a priori* (comme cela est présenté *supra*),\n",
    "- fixer un seuil de distance: en modifiant légèrement l'algorithme précédant il est possible de stopper les aggrégations dès qu'une distance seuil inter-clusters est atteinte. Le nombre $k$ de clusters n'a alors pas à être défini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering par partitionnement : K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif de l'approche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le clustering par partionnement consiste à trouver une partition optimisant un critère de qualité.\n",
    "\n",
    "Nous ne traiterons ici que des approches pour lesquelles le nombre de partitions à trouver sont fixées *a priori* et pour lesquelles les partitions sont non recouvrantes (un point ne peut appartenir à plusieurs clusters).\n",
    "\n",
    "Donc, étant donné:\n",
    "- $\\mathcal{D}=\\{x_i \\in \\mathbb{R}^d \\}_{i=1..N}$ un ensemble de $N$ points de dimensions $d$ format le jeux de données $\\mathcal{D}$ a partitionner,\n",
    "- $k$ le nombre de clusters de la partition $C=\\{c_i\\}_{i=1..k}$ avec $k\\leq N$\n",
    "- $Q$ une fonction de qualité à optimiser\n",
    "\n",
    "L'objectif est de déterminer la meilleure partition $C$ au sens du critère de qualité de la fonction $Q$ en $k$ clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche exacte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une approche exacte garantie que l'on obtient la meilleurs solution.\n",
    "\n",
    "Pour le problème de partitionnement qui nous occupe, cela demande:\n",
    "1. de construire toutes les partitions possibles\n",
    "2. évaluer la qualité de chaque partionnement (clustering) pour ne retenir que la meilleure.\n",
    "\n",
    "Le problème avec cette approche est qu'elle est rapidement inenvisageable lorsque le nombre de points à partitionner augmente.\n",
    "\n",
    "En effet, le nombre de partitions augment exponentiellement (il est défini par le nombre de Stirling de seconde espèce):\n",
    "\n",
    "$$ \\#Clusters = \\frac{1}{k!} \\sum_{i=1}^{k} (-1)^{k-i} C^{k}_{i} i^N $$\n",
    "\n",
    "Ainsi, \n",
    "- pour $N=10$ et $k=4$ on a $$\\#Clusters = 34.105$$\n",
    "- pour $N=20$ et $k=4$ on a $$\\#Clusters = 45.232.115.901$$\n",
    "- pour $N=30$ et $k=4$ on a $$\\#Clusters = 48.004.081.105.038.305$$\n",
    "- pour $N=100$ et $k=4$ on a $$\\#Clusters = 66.955.751.844.038.698.560.793.085.292.692.610.900.187.911.879.206.859.351.901$$\n",
    "\n",
    "Il parait donc évident que l'approche exacte n'est pas adapée pour les jeux de données usuels, même de petite taille, car le nombre de calculs à faire n'est pas réalisable, même pour le plus puissant des ordinateurs.\n",
    "\n",
    "Il est donc nécessaire de mettre en place une approche heuristique permettant d'obtenir une bonne partition (qui n'est donc pas forcement la meilleure) dans un temps raisonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe de l'algorithme du K-means (K-Moyennes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme du k-means (k-moyennes) [Wikipedia](https://fr.wikipedia.org/wiki/K-moyennes) est un algorithme de de partitionnement paramétrable permettant souvent l'obtention de bonnes partitions des données.\n",
    "\n",
    "Cet algorthime utilise comme mesure de qualité d'un partitionnement l'inertie intra-classes de la partition. On rappelle que cette intertie est calculée comme la somme des inerties intra-classes de tous les clusters:\n",
    "\n",
    "\\begin{align}\n",
    "J_{W} & = \\sum_{C_k \\in \\mathcal{C}} J_k\\\\\n",
    "    & = \\sum_{C_k \\in \\mathcal{C}} \\sum_{x\\in C_k}dist^2(x,\\mu_k)\n",
    "\\end{align}\n",
    "\n",
    "Cet algorithme:\n",
    "1. évite une énumération de toutes les partitions possibles\n",
    "2. utilise une approche heuristique permettant l'obtention d'une bonne partition (au sens de la minimisation de $J_{W}$) par convergence.\n",
    "\n",
    "Le principe de l'algorithme consiste à trouver k clusters minimisant la distances entre les points de chaque clusters.\n",
    "\n",
    "Il proçède de la façon suivante:\n",
    "- si l'on connait les centres de gravité $\\mu_k$ des $k$ clusters $\\{c_j\\}_{j=1..k}$:\n",
    "    - on affecte chaque point $x_i$ au cluster $c_j$ dont il est le plus proche (au sens de la distance entre $x_i$ et $\\mu_j$)\n",
    "    - une fois tous les points attribué à un cluster on recalcule les centres de gravités $\\mu_j$ de chaque cluster comme le barycentre des points du cluster $c_j$\n",
    "On réitère cette opération jusqu'à convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:midnightblue\">\n",
    "\n",
    "<u>**Remarque 1 :**</u>\n",
    "\n",
    "Pour que cet algorithme fonctionne il faut lui fournir au départ autant de centre de gravité qu'il y a de clusters.\n",
    "Cette étape s'appelle l'initialisation.\n",
    "Il est important de noter que le choix des centres de gravité initiaux peut dans certaines situations fortement conditionner le contenu final des clusters. Autrement dit, des centres de gravité initiaux différents peuvent conduire à des clustering différents...\n",
    "\n",
    "<u>**Remarque 2 :**</u>\n",
    "\n",
    "C'est en général la *distance euclidienne* $dist_E(x_i,c_j)$ qui est utilisée pour identifier le cluster le plus proche d'un point.\n",
    "\n",
    "<u>**Remarque 3 :**</u>\n",
    "\n",
    "La convergence est obtenue lorsque deux itérations successives ne modifient plus les centres des clusters. Toutefois, cette convergence peux être longue à atteindre. Afin d'obtenir une partition dans un délais raisonable il peut donc être utile d'introduire un critére de convergence, qui lorsqu'il est atteint stope le calcul.\n",
    "\n",
    "Les critères de convergence qui permettent de stoper les itérations de cette heuristique qui sont généralement choisis: \n",
    "- atteindre une valeur seuil $\\epsilon$ de l'inertie intra-classe $||J_W||$ de la partition à atteindre,\n",
    "- atteindre une valeur seuil $\\epsilon2$ de la variation de l'inertie intra-classe entre 2 itérations successives $||J_W^{n} - J_W^{n+1}||$ de l'algorithme,\n",
    "- la plus fréquente consiste à borner le nombre d'itération : si la convergence n'est pas atteinte au bout de $max{iter} pas on stoppe et on retourne le clustering ainsi obtenu.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de déroulement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "\n",
    "<u>***Cas d'étude:***</u>\n",
    "\n",
    "Nous reprendrons ici le cas d'étude utilisé lors de la présentation de la classification hiérarchique ascendante.\n",
    "\n",
    "Soit un jeu de données $\\mathcal{D}$ contenant $N=12$ étudiants \n",
    "$$\\mathcal{D}=\\left\\{x_i\\right\\}_{12 (i\\in 1\\text{..})}=\\left\\{x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10},x_{11},x_{12}\\right\\}$$\n",
    "où chaque étudiant est décrit par les moyennes de $d=2$ UE. On a : \n",
    "$$\\mathcal{D}=\\{(1 , 6 ),(1 , 7 ),(1 , 8 ),(3 , 3 ),(3 , 4 ),(4 , 2 ),(5 , 2 ),(6 , 3 ),(7 , 3 ),(9 , 6 ),(9 , 7 ),(9 , 8 )\\}$$\n",
    "Chaque étudiant est représenté dans le plan par un point en 2D. Voici une représentation des étudiants :\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkVUlEQVR4nO3df3AU9f3H8dflOC4EkmjANIkEDFLUENFaQkH5VlsNUjGjtaVVoEbTnxp/IFOr1VoSFZF2dOzoFEUrpWUibUex0pZoLBV1akyQYkGoSo0/qkEmE80RAueR2+8fTNJGEsiF993ebZ6PmUxmP+7tvt93K59XdjdZn+M4jgAAAAykuV0AAADwDoIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzAxL9A6j0ag++OADZWZmyufzJXr3AABgEBzH0Z49e1RQUKC0tP7PSyQ8WHzwwQcqLCxM9G4BAICB9957T2PHju33vyc8WGRmZko6WFhWVpbZdiORiJ555hnNmjVLgUDAbLvJxOs90l/q83qP9Jf6vN5jPPsLhUIqLCzsmcf7k/Bg0X35IysryzxYZGRkKCsry5MHi+T9Hukv9Xm9R/pLfV7vMRH9Hek2Bm7eBAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMOOJYNEVddTY3CZJamxuU1fUcbkiAAASK1nmwpiCxYEDB/STn/xERUVFGjFihCZMmKDbb79d0Wg0XvUdUd22Fs1ctkGVq5okSZWrmjRz2QbVbWtxrSYAABIpmebCmILFsmXL9OCDD+qBBx7Qjh079LOf/Uw///nPdf/998ervsOq29aiq1ZvVkv7/l7ju9r366rVmwkXAADPS7a5MKZg8dJLL+miiy7SnDlzdMIJJ+jrX/+6Zs2apU2bNsWrvn51RR3VrNuuvk70dI/VrNvOZREAgGcl41wY00PIZs6cqQcffFBvvPGGJk2apFdffVUvvvii7rvvvn5fEw6HFQ6He5ZDoZCkgw9KiUQig6taB68ftXXsU9B/cDmY5vT6LkltHfvUsHO3phXlDHo/yaT7/Tqa9y2Z0V/q83qP9Jf6vNZjIufCgb5nPsdxBhxjHMfRLbfcomXLlsnv96urq0tLlizRj3/8435fU11drZqamkPGa2trlZGRMdBdAwAAF3V2dmrevHlqb28/7NPJYwoWa9as0Y033qif//znmjx5srZs2aKFCxfq3nvvVUVFRZ+v6euMRWFhoVpbW4/qsemNzW09N6lIB9PZHVOjum1TmsLR/z7S9dGKUk+dsaivr1dZWZlnH/dLf6nN6z3SX+rzWo+JnAtDoZDGjBlzxGAR06WQG2+8UTfffLMuvfRSSdKpp56qd955R0uXLu03WASDQQWDwUPGA4HAUX2o0yfmKmfUCO1q39/r2lI46lO4yyefpLzsdE2fmCt/2uGfHZ9qjva9S3b0l/q83iP9pT6v9JjIuXCg71dMN292dnYqLa33S/x+vyu/bupP82lxebEk6dNvVffy4vJiz4UKAAC6JeNcGFOwKC8v15IlS/TnP/9Zb7/9ttauXat7771XX/3qV+NV32HNLsnX8gVnKC87vdd4Xna6li84Q7NL8l2pCwCAREm2uTCmSyH333+/brvtNl199dXavXu3CgoK9P3vf18//elP41XfEc0uyVdZcZ4adu5W644GPVpR6snLHwAA9CeZ5sKYgkVmZqbuu+++w/56qRv8aT5NK8rRX3ZI04pyCBUAgCEnWeZCTzwrBAAAJAeCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADAjCeCRVfUUWNzmySpsblNXVHH5YoAAEisZJkLYwoWJ5xwgnw+3yFfVVVV8arviOq2tWjmsg2qXNUkSapc1aSZyzaobluLazUBAJBIyTQXxhQsmpqa1NLS0vNVX18vSZo7d25cijuSum0tumr1ZrW07+81vqt9v65avZlwAQDwvGSbC2MKFscdd5zy8vJ6vv70pz/pxBNP1Nlnnx2v+vrVFXVUs267+jrR0z1Ws247l0UAAJ6VjHPhsMG+8JNPPtHq1au1aNEi+Xy+ftcLh8MKh8M9y6FQSJIUiUQUiUQGu3s1NreprWOfgv6Dy8E0p9d3SWrr2KeGnbs1rShn0PtJJt3v19G8b8mM/lKf13ukv9TntR4TORcO9D3zOY4zqBjz+9//XvPmzdO7776rgoKCfterrq5WTU3NIeO1tbXKyMgYzK4BAECCdXZ2at68eWpvb1dWVla/6w06WJx//vkaPny41q1bd9j1+jpjUVhYqNbW1sMWdiSNzW09N6lIB9PZHVOjum1TmsLR/55BebSi1FNnLOrr61VWVqZAIOB2OeboL/V5vUf6S31e6zGRc2EoFNKYMWOOGCwGdSnknXfe0bPPPqsnnnjiiOsGg0EFg8FDxgOBwFF9qNMn5ipn1Ajtat/f69pSOOpTuMsnn6S87HRNn5grf1r/l2pS0dG+d8mO/lKf13ukv9TnlR4TORcO9P0a1N+xWLlypXJzczVnzpzBvNyEP82nxeXFkqRPv1Xdy4vLiz0XKgAA6JaMc2HMwSIajWrlypWqqKjQsGGDvvfTxOySfC1fcIbystN7jedlp2v5gjM0uyTfpcoAAEiMZJsLY04Gzz77rN59911VVlbGo56YzS7JV1lxnhp27lbrjgY9WlHqycsfAAD0J5nmwpjPWMyaNUuO42jSpEnxqGdQ/Gm+nptSphXlECoAAENOssyFnnhWCAAASA4ECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGU8Ei66oo8bmNklSY3ObuqKOyxUBAJBYyTIXxhws3n//fS1YsECjR49WRkaGTj/9dL3yyivxqG1A6ra1aOayDapc1SRJqlzVpJnLNqhuW4trNQEAkEjJNBfGFCw++ugjnXXWWQoEAlq/fr22b9+ue+65R8ccc0ycyju8um0tumr1ZrW07+81vqt9v65avZlwAQDwvGSbC4fFsvKyZctUWFiolStX9oydcMIJ1jUNSFfUUc267errRI8jySepZt12lRXnyZ/mS3B1AADEXzLOhTEFi6eeekrnn3++5s6dq40bN+r444/X1Vdfre9+97v9viYcDiscDvcsh0IhSVIkElEkEhlk2QevH7V17FPQf3A5mOb0+i5JbR371LBzt6YV5Qx6P8mk+/06mvctmdFf6vN6j/SX+rzWYyLnwoG+Zz7HcQZ8d0d6erokadGiRZo7d64aGxu1cOFCPfTQQ7r88sv7fE11dbVqamoOGa+trVVGRsZAdw0AAFzU2dmpefPmqb29XVlZWf2uF1OwGD58uKZOnaq///3vPWPXXXedmpqa9NJLL/X5mr7OWBQWFqq1tfWwhR1JY3Nbz00q0sF0dsfUqG7blKZw9L+nex6tKPXUGYv6+nqVlZUpEAi4XY45+kt9Xu+R/lKf13pM5FwYCoU0ZsyYIwaLmC6F5Ofnq7i4uNfYKaecoscff7zf1wSDQQWDwUPGA4HAUX2o0yfmKmfUCO1q39/r2lI46lO4yyefpLzsdE2fmOu5eyyO9r1LdvSX+rzeI/2lPq/0mMi5cKDvV0y/FXLWWWfp9ddf7zX2xhtvaPz48bFsxoQ/zafF5QdDzqffqu7lxeXFngsVAAB0S8a5MKZgccMNN6ihoUF33XWXdu7cqdraWq1YsUJVVVXxqu+wZpfka/mCM5SXnd5rPC87XcsXnKHZJfmu1AUAQKIk21wY06WQ0tJSrV27Vj/+8Y91++23q6ioSPfdd5/mz58fr/qOaHZJvsqK89Swc7dadzTo0YpST17+AACgP8k0F8YULCTpwgsv1IUXXhiPWgbNn+bTtKIc/WWHNK0oh1ABABhykmUu9MSzQgAAQHIgWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAmZiCRXV1tXw+X6+vvLy8eNUGAABSzLBYXzB58mQ9++yzPct+v9+0IAAAkLpiDhbDhg3jLAUAAOhTzMHizTffVEFBgYLBoL7whS/orrvu0oQJE/pdPxwOKxwO9yyHQiFJUiQSUSQSGUTJfeveluU2k43Xe6S/1Of1Hukv9Xm9x3j2N9Bt+hzHcQa60fXr16uzs1OTJk3Shx9+qDvvvFP/+te/9Nprr2n06NF9vqa6ulo1NTWHjNfW1iojI2OguwYAAC7q7OzUvHnz1N7erqysrH7XiylYfNrevXt14okn6kc/+pEWLVrU5zp9nbEoLCxUa2vrYQuLVSQSUX19vcrKyhQIBMy2m0y83iP9pT6v90h/qc/rPcazv1AopDFjxhwxWMR8KeR/jRw5UqeeeqrefPPNftcJBoMKBoOHjAcCgbh8qPHabjLxeo/0l/q83iP9pT6v9xiP/ga6vaP6OxbhcFg7duxQfn7+0WwGAAB4REzB4oc//KE2btyo5uZmvfzyy/r617+uUCikioqKeNUHAABSSEyXQv7zn//osssuU2trq4477jhNnz5dDQ0NGj9+fLzqAwAAKSSmYLFmzZp41QEAADyAZ4UAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBZJCV9RRY3ObJKmxuU1dUcfligAAg3FUwWLp0qXy+XxauHChUTkYiuq2tWjmsg2qXNUkSapc1aSZyzaobluLy5UBAGI16GDR1NSkFStWaMqUKZb1YIip29aiq1ZvVkv7/l7ju9r366rVmwkXAJBiBhUsOjo6NH/+fD388MM69thjrWvCENEVdVSzbrv6uujRPVazbjuXRQAghQwbzIuqqqo0Z84cnXfeebrzzjsPu244HFY4HO5ZDoVCkqRIJKJIJDKY3fepe1uW20w2XuuxsblNbR37FPQfXA6mOb2+S1Jbxz417NytaUU5bpRoymufX1+83iP9pT6v9xjP/ga6TZ/jODH9OLhmzRotWbJETU1NSk9P1znnnKPTTz9d9913X5/rV1dXq6am5pDx2tpaZWRkxLJrAADgks7OTs2bN0/t7e3Kysrqd72YgsV7772nqVOn6plnntFpp50mSUcMFn2dsSgsLFRra+thC4tVJBJRfX29ysrKFAgEzLabTLzWY2NzW88Nm9LBMxV3TI3qtk1pCkd9PeOPVpR65oyFlz6/vni9R/pLfV7vMZ79hUIhjRkz5ojBIqZLIa+88op2796tz3/+8z1jXV1dev755/XAAw8oHA7L7/f3ek0wGFQwGDxkW4FAIC4fary2m0y80uP0ibnKGTVCu9r397rPIhz1Kdzlk09SXna6pk/MlT/N199mUo5XPr/D8XqP9Jf6vN5jPPob6PZiunnz3HPP1datW7Vly5aer6lTp2r+/PnasmXLIaECOBx/mk+Ly4slSZ+ODd3Li8uLPRUqAMDrYjpjkZmZqZKSkl5jI0eO1OjRow8ZBwZidkm+li84QzXrtqutY1/PeF52uhaXF2t2Sb6L1QEAYjWo3woBLM0uyVdZcZ4adu5W644GPVpR6rnLHwAwVBx1sHjuuecMysBQ50/zaVpRjv6yQ5pWlEOoAIAUxbNCAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQJJoSvqqLG5TZLU2NymrqjjckVAb14/Rr3eHxInpmCxfPlyTZkyRVlZWcrKytKMGTO0fv36eNWGIaJuW4tmLtugylVNkqTKVU2auWyD6ra1uFwZcJDXj1Gv94fEiilYjB07Vnfffbc2bdqkTZs26ctf/rIuuugivfbaa/GqDx5Xt61FV63erJb2/b3Gd7Xv11WrN/MPG1zn9WPU6/0h8WIKFuXl5brgggs0adIkTZo0SUuWLNGoUaPU0NAQr/rgYV1RRzXrtquvE67dYzXrtnNKFq7x+jHq9f7gjmGDfWFXV5f+8Ic/aO/evZoxY0a/64XDYYXD4Z7lUCgkSYpEIopEIoPd/SG6t2W5zWTjtR4bm9vU1rFPQf/B5WCa0+u7JLV17FPDzt2aVpTjRommvPb59cVrPXr9GPV6f33x2jH6afHsb6Db9DmOE1MU3bp1q2bMmKH9+/dr1KhRqq2t1QUXXNDv+tXV1aqpqTlkvLa2VhkZGbHsGgAAuKSzs1Pz5s1Te3u7srKy+l0v5mDxySef6N1339XHH3+sxx9/XI888og2btyo4uLiPtfv64xFYWGhWltbD1tYrCKRiOrr61VWVqZAIGC23WTitR4bm9t6bhaTDv6UdMfUqG7blKZw1Ncz/mhFqSd+WvLa59cXr/Xo9WPU6/31xWvH6KfFs79QKKQxY8YcMVjEfClk+PDhmjhxoiRp6tSpampq0i9+8Qs99NBDfa4fDAYVDAYPGQ8EAnH5UOO13WTilR6nT8xVzqgR2tW+v9c13nDUp3CXTz5Jednpmj4xV/40X3+bSTle+fwOxys9ev0Y9Xp/h+OVY7Q/8ehvoNs76r9j4ThOrzMSwED503xaXH7wTNen/8nqXl5cXuy5f9CQOrx+jHq9P7gjpmBxyy236IUXXtDbb7+trVu36tZbb9Vzzz2n+fPnx6s+eNzsknwtX3CG8rLTe43nZadr+YIzNLsk36XKgIO8fox6vT8kXkyXQj788EN961vfUktLi7KzszVlyhTV1dWprKwsXvVhCJhdkq+y4jw17Nyt1h0NerSi1JOnXpG6vH6Mer0/JFZMweJXv/pVvOrAEOdP82laUY7+skOaVpTDP2hIOl4/Rr3eHxKHZ4UAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBZAAXVFHjc1tkqTG5jZ1RR2XK7I3FHoEcGQxBYulS5eqtLRUmZmZys3N1cUXX6zXX389XrUBnlC3rUUzl21Q5aomSVLlqibNXLZBddtaXK7MzlDoEcDAxBQsNm7cqKqqKjU0NKi+vl4HDhzQrFmztHfv3njVB6S0um0tumr1ZrW07+81vqt9v65avdkTE+9Q6BHAwA2LZeW6urpeyytXrlRubq5eeeUVffGLXzQtDEh1XVFHNeu2q68LAo4kn6SaddtVVpwnf5ovwdXZGAo9AohNTMHi09rb2yVJOTk5/a4TDocVDod7lkOhkCQpEokoEokcze576d6W5TaTjdd79Fp/jc1tauvYp6D/4HIwzen1XZLaOvapYeduTSvq//+hZDYUevxfXjtGP83r/Une7zGe/Q10mz7HcQZ1h5XjOLrooov00Ucf6YUXXuh3verqatXU1BwyXltbq4yMjMHsGgAAJFhnZ6fmzZun9vZ2ZWVl9bveoINFVVWV/vznP+vFF1/U2LFj+12vrzMWhYWFam1tPWxhsYpEIqqvr1dZWZkCgYDZdpOJ13v0Wn+NzW09NzNKB3+Kv2NqVLdtSlM4+t/LAo9WlKbsT/NDocf/5bVj9NO83p/k/R7j2V8oFNKYMWOOGCwGdSnk2muv1VNPPaXnn3/+sKFCkoLBoILB4CHjgUAgLh9qvLabTLzeo1f6mz4xVzmjRmhX+/5e9yCEoz6Fu3zyScrLTtf0ibkpe//BUOixL145Rvvj9f4k7/cYj/4Gur2YfivEcRxdc801euKJJ7RhwwYVFRUNqjhgKPCn+bS4vFjSwZsY/1f38uLy4pSecIdCjwBiE1OwqKqq0urVq1VbW6vMzEzt2rVLu3bt0r59++JVH5DSZpfka/mCM5SXnd5rPC87XcsXnKHZJfkuVWZnKPQIYOBiuhSyfPlySdI555zTa3zlypW64oorrGoCPGV2Sb7KivPUsHO3Wnc06NGKUs9dGhgKPQIYmJiCxSDv8wSGPH+aT9OKcvSXHdK0ohxPTrhDoUcAR8azQgAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgJlBPd30aHT/9c5QKGS63Ugkos7OToVCIc8+sc7rPdJf6vN6j/SX+rzeYzz76563j/RXuBMeLPbs2SNJKiwsTPSuAQDAUdqzZ4+ys7P7/e8+J8EPAIlGo/rggw+UmZkpn8/uWQKhUEiFhYV67733lJWVZbbdZOL1Hukv9Xm9R/pLfV7vMZ79OY6jPXv2qKCgQGlp/d9JkfAzFmlpaRo7dmzctp+VleXJg+V/eb1H+kt9Xu+R/lKf13uMV3+HO1PRjZs3AQCAGYIFAAAw45lgEQwGtXjxYgWDQbdLiRuv90h/qc/rPdJf6vN6j8nQX8Jv3gQAAN7lmTMWAADAfQQLAABghmABAADMECwAAICZlA8Wzz//vMrLy1VQUCCfz6cnn3zS7ZJMLV26VKWlpcrMzFRubq4uvvhivf76626XZWb58uWaMmVKzx9zmTFjhtavX+92WXGzdOlS+Xw+LVy40O1SzFRXV8vn8/X6ysvLc7ssc++//74WLFig0aNHKyMjQ6effrpeeeUVt8syccIJJxzyGfp8PlVVVbldmokDBw7oJz/5iYqKijRixAhNmDBBt99+u6LRqNulmdmzZ48WLlyo8ePHa8SIETrzzDPV1NTkSi0J/8ub1vbu3avTTjtNV155pb72ta+5XY65jRs3qqqqSqWlpTpw4IBuvfVWzZo1S9u3b9fIkSPdLu+ojR07VnfffbcmTpwoSVq1apUuuugi/eMf/9DkyZNdrs5WU1OTVqxYoSlTprhdirnJkyfr2Wef7Vn2+/0uVmPvo48+0llnnaUvfelLWr9+vXJzc/Xvf/9bxxxzjNulmWhqalJXV1fP8rZt21RWVqa5c+e6WJWdZcuW6cEHH9SqVas0efJkbdq0SVdeeaWys7N1/fXXu12eie985zvatm2bfvvb36qgoECrV6/Weeedp+3bt+v4449PbDGOh0hy1q5d63YZcbV7925HkrNx40a3S4mbY4891nnkkUfcLsPUnj17nM9+9rNOfX29c/bZZzvXX3+92yWZWbx4sXPaaae5XUZc3XTTTc7MmTPdLiNhrr/+eufEE090otGo26WYmDNnjlNZWdlr7JJLLnEWLFjgUkW2Ojs7Hb/f7/zpT3/qNX7aaac5t956a8LrSflLIUNNe3u7JCknJ8flSux1dXVpzZo12rt3r2bMmOF2Oaaqqqo0Z84cnXfeeW6XEhdvvvmmCgoKVFRUpEsvvVRvvfWW2yWZeuqppzR16lTNnTtXubm5+tznPqeHH37Y7bLi4pNPPtHq1atVWVlp+qBIN82cOVN//etf9cYbb0iSXn31Vb344ou64IILXK7MxoEDB9TV1aX09PRe4yNGjNCLL76Y8HpS/lLIUOI4jhYtWqSZM2eqpKTE7XLMbN26VTNmzND+/fs1atQorV27VsXFxW6XZWbNmjXavHmza9c74+0LX/iCfvOb32jSpEn68MMPdeedd+rMM8/Ua6+9ptGjR7tdnom33npLy5cv16JFi3TLLbeosbFR1113nYLBoC6//HK3yzP15JNP6uOPP9YVV1zhdilmbrrpJrW3t+vkk0+W3+9XV1eXlixZossuu8zt0kxkZmZqxowZuuOOO3TKKafoM5/5jB577DG9/PLL+uxnP5v4ghJ+jiSO5PFLIVdffbUzfvx457333nO7FFPhcNh58803naamJufmm292xowZ47z22mtul2Xi3XffdXJzc50tW7b0jHntUsindXR0OJ/5zGece+65x+1SzAQCAWfGjBm9xq699lpn+vTpLlUUP7NmzXIuvPBCt8sw9dhjjzljx451HnvsMeef//yn85vf/MbJyclxfv3rX7tdmpmdO3c6X/ziFx1Jjt/vd0pLS5358+c7p5xySsJrIVikiGuuucYZO3as89Zbb7ldStyde+65zve+9z23yzCxdu3anv/Ru78kOT6fz/H7/c6BAwfcLjEuzjvvPOcHP/iB22WYGTdunPPtb3+719gvf/lLp6CgwKWK4uPtt9920tLSnCeffNLtUkyNHTvWeeCBB3qN3XHHHc5JJ53kUkXx09HR4XzwwQeO4zjON77xDeeCCy5IeA1cCklyjuPo2muv1dq1a/Xcc8+pqKjI7ZLiznEchcNht8swce6552rr1q29xq688kqdfPLJuummmzz32xOSFA6HtWPHDv3f//2f26WYOeussw75Ne833nhD48ePd6mi+Fi5cqVyc3M1Z84ct0sx1dnZqbS03rcU+v1+T/26abeRI0dq5MiR+uijj/T000/rZz/7WcJrSPlg0dHRoZ07d/YsNzc3a8uWLcrJydG4ceNcrMxGVVWVamtr9cc//lGZmZnatWuXJCk7O1sjRoxwubqjd8stt+grX/mKCgsLtWfPHq1Zs0bPPfec6urq3C7NRGZm5iH3w4wcOVKjR4/2zH0yP/zhD1VeXq5x48Zp9+7duvPOOxUKhVRRUeF2aWZuuOEGnXnmmbrrrrv0jW98Q42NjVqxYoVWrFjhdmlmotGoVq5cqYqKCg0blvJTQy/l5eVasmSJxo0bp8mTJ+sf//iH7r33XlVWVrpdmpmnn35ajuPopJNO0s6dO3XjjTfqpJNO0pVXXpn4YhJ+jsTY3/72N0fSIV8VFRVul2air94kOStXrnS7NBOVlZXO+PHjneHDhzvHHXecc+655zrPPPOM22XFldfusfjmN7/p5OfnO4FAwCkoKHAuueQSz9wj87/WrVvnlJSUOMFg0Dn55JOdFStWuF2SqaefftqR5Lz++utul2IuFAo5119/vTNu3DgnPT3dmTBhgnPrrbc64XDY7dLM/O53v3MmTJjgDB8+3MnLy3Oqqqqcjz/+2JVaeGw6AAAww9+xAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAz/w9lHI/u9E2JFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D=[(1,6),(1,7),(1,8),(3,3),(3,4),(4,2),(5,2),(6,3),(7,3),(9,6),(9,7),(9,8)]\n",
    "\n",
    "plt.scatter([pt[0] for pt in D], [pt[1] for pt in D])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:indianred\">\n",
    "On va fixer $k = 3$ dans cet exemple. La distance entre points utilisée est la distance euclidienne.</br></br>\n",
    "\n",
    "\n",
    "<u>***Initialisation des centres mobiles*** :</u>    \n",
    "L'étape d'initialisation consiste à définir autant de centroïdes initiaux qu'il a de cluster à former. Ici nous tirons aléatoirement les centroïdes (les coordonnées des centroïdes sont aléatoires). Soit les centroïdes initiaux suivants :\n",
    "$$M=\\{\\mu _1,\\mu _2,\\mu _3\\}=\\{(3,5),(3,10),(8.5,4)\\}$$\n",
    "\n",
    "1. <u>***Itération 1*** :</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_1_1.png\" width=75%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_1_2.png\" width=75%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_1_3.png\" width=45%>\n",
    "    \n",
    "2. <u>***Itération 2*** : Les centroïdes ont été modifiés lors de l'itération donc on continue.</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_2_1.png\" width=80%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_2_2.png\" width=80%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_3_3.png\" width=45%>\n",
    "    \n",
    "3. <u>***Itération 3*** : Les centroïdes ont été modifiés lors de l'itération donc on continue</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_3_1.png\" width=80%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_3_2.png\" width=80%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_3_3.png\" width=45%>\n",
    "    \n",
    "4. <u>***Itération 4*** : Les centroïdes ont été modifiés lors de l'itération donc on continue</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_4_1.png\" width=75%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_4_2.png\" width=75%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_4_3.png\" width=45%>\n",
    "    \n",
    "5. <u>***Itération 5*** : Les centroïdes ont été modifiés lors de l'itération donc on continue</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_5_1.png\" width=75%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_5_2.png\" width=75%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_5_3.png\" width=45%>\n",
    "    \n",
    "6. <u>***Itération 6*** : Les centroïdes ont été modifiés lors de l'itération donc on continue</u>    \n",
    "    1. Calcul de la distance de chaque points à chacun des $k=3$ centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_6_1.png\" width=75%>\n",
    "    \n",
    "    2. Formation des clusters : chaque point $x_i$ de $\\mathcal{D}$ est affecté au cluster $k$ dont si le point est plus proche du centroïde $\\mu_k$ que des autres centroïdes $\\mu_j$ :\n",
    "    \n",
    "    <img src=\"img/ex_km_6_2.png\" width=75%>\n",
    "    \n",
    "    3. Actualisation des positions des centroïdes :\n",
    "    \n",
    "    <img src=\"img/ex_km_6_3.png\" width=45%>\n",
    "    \n",
    "7. <u>***Itération 7*** : Les centroïdes n'ont pas été modifiés lors de l'itération donc on arrête !!!</u>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Autres exemples de déroulement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour k=4:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"img/kmean_4.gif\"></br>\n",
    "</p>\n",
    "\n",
    "Pour k=7:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"img/kmean_7.gif\"></br>\n",
    "</p>\n",
    "\n",
    "Pour k=8:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"img/kmean_8.gif\"></br>\n",
    "</p>\n",
    "\n",
    "Pour k=8:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"img/kmean_8_2.gif\"></br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L'algorithme du K-mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Input**</u>\n",
    "- $\\mathcal{D}$ un jeu de données\n",
    "- $k$ le nombre de classe à former.\n",
    "- $\\mathcal{M}=\\{\\mu_1, \\mu_2, ..., \\mu_k\\}$ un ensemble initial de centres de clusters (centroides / centres mobiles)\n",
    "\n",
    "<u>**Output**</u>\n",
    "- une classification $\\mathcal{C}$ contenant $k$ classes/clusters\n",
    "\n",
    "<u>**Algorithme**</u>\n",
    "- Initialisation: \n",
    "\n",
    "- Tant qu'il n'y a pas convergence:\n",
    "    - Mettre ou Former la partition en associant chaque point $x_i$ au cluster dont le centre est le plus proche:\n",
    "    $$\\mathcal{C}=\\{c_j=\\{x_i, ||x_i-\\mu_j|| \\leq ||x_i-\\mu_{j'}|| \\forall j'=1..k\\}\\}$$\n",
    "    - Recalculer les centres des clusters:\n",
    "    $$\\mathcal{M}=\\{\\mu_j=\\frac{1}{n_j}\\sum_{i\\in c_k}x_i\\}_{j=1..k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:midnightblue\">\n",
    "\n",
    "<u>**Remarque 1 :**</u>\n",
    "Plusieurs stratégies peuvent être mises en oeuvre pour choisir la position intiale des centres de clusters, parmi lesquelles:\n",
    "- choisir des positions aléatoires pour les centres.\n",
    "- attribuer aléatoirement chaque point à un cluster et calculer son centre,\n",
    "- choisir k points du jeu de données et les définir comme les centres des clusters initiaux.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "<span style=\"color:darkgreen\">\n",
    "    \n",
    "<u>**Exercice(s) :**</u>\n",
    "\n",
    "- Exercice TD : Déroulement du KMeans\n",
    "- Exercice TP: Programmation du KMeans\n",
    "- Exercice TP: Application du KMeans\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
